install.packages("tidyverse")
#LDA analysis in R
setwd("C:/Users/matth/Full_Study/")
library(tidyverse)
library(lubridate)
dat2018<- read.csv("C:/Users/matth/Full_Study/processed2018.csv")
dat2019<- read.csv("C:/Users/matth/Full_Study/processed2019.csv")
dat2020<- read.csv("C:/Users/matth/Full_Study/processed2020.csv")
allData<- rbind(dat2018, dat2019, dat2020) %>% mutate(newDate=as.Date(date)) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
group_by(tweetYear) %>% mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
ungroup()
#Pull out the top 200 tweets in each topic to aid in naming the topics
representativeTweets<- allData %>% group_by(Dominant_Topic) %>% top_n(200, Perc_Contribution)
data.table::fwrite(representativeTweets, file="representativeTweets.csv")
#compare June "stop smoking" and "quit smoking" to see if there's overlap
juneSS1<- read.csv("C:/Users/matth/Yearly_Twitter/junSS2020_1.csv")
juneSS2<- read.csv("C:/Users/matth/Yearly_Twitter/junSS2020_2.csv")
juneQS1<- read.csv("C:/Users/matth/Yearly_Twitter/junQS2020_1.csv")
juneQS2<- read.csv("C:/Users/matth/Yearly_Twitter/junSS2020_2.csv")
juneSSAll <- rbind(juneSS1, juneSS2) %>% select(id, ) #21.7k tweets
juneQSAll <- rbind(juneQS1, juneQS2) %>% select(id) #17.8k tweets
allTweets <- inner_join(juneSSAll, juneQSAll) #11.6 k tweets are in both
allData <- allData %>% mutate(tweetYear= as.factor(tweetYear), tweetMonth= as.factor(tweetMonth), tweetWeek = as.factor(tweetWeek))
reducedData <- allData %>% group_by(tweetYear) %>% count(tweetMonth, name="monthlyTweets")  %>% mutate(yearlyMax= max(monthlyTweets)) %>%
mutate(scaledProp= (monthlyTweets/yearlyMax)*100)
filteredData <- allData %>% filter(Dominant_Topic %in% c(0,3,6,8,9,10)) %>% group_by(tweetYear, tweetMonth) %>% count(Dominant_Topic) %>%
group_by(Dominant_Topic) %>% mutate(topicMax= max(n)) %>% mutate(scaledProp= (n/topicMax)*100) %>%
mutate(newTweetMonth= ifelse(tweetYear==2019, as.numeric(tweetMonth) + 12, ifelse(tweetYear==2020, as.numeric(tweetMonth) +24, as.numeric(tweetMonth)))) %>%
mutate(newTweetMonth = as.factor(newTweetMonth), Dominant_Topic = as.factor(Dominant_Topic))
ifelse(Dominant_Topic==10, "10 - Experiences", "NA"))))))
reformatted<- filteredData %>% mutate(newTopicNames= ifelse(Dominant_Topic==0, "0 - Campaign",
ifelse(Dominant_Topic==3, "3 - Benefits",
ifelse(Dominant_Topic==6, "6 - Difficulty",
ifelse(Dominant_Topic==8, "8 - Methods",
ifelse(Dominant_Topic==9, "9 - E-cigs",
ifelse(Dominant_Topic==10, "10 - Experiences", "NA")))))))
table(reformatted$newTopicNames)
View(reformatted)
ggplot(reformatted, aes(x=newTweetMonth, y=n, group=newTopicNames)) +
geom_point(stat="identity", size=3, aes(shape=newTopicNames)) +
geom_line(stat="identity", aes(color=newTopicNames)) +
labs(title="Selected Topic Trends", shape="Topic", color="Topic") +
theme(plot.title = element_text(hjust = 0.5)) +
xlab("Month") +
ylab("Total Tweets")
ggplot(reformatted, aes(x=newTweetMonth, y=n, group=newTopicNames)) +
geom_point(stat="identity", size=3, aes(shape=newTopicNames)) +
geom_line(stat="identity", aes(color=newTopicNames)) +
labs(title="Selected Topic Trends", shape="Topic", color="Topic") +
theme(plot.title = element_text(hjust = 0.5)) +
xlab("Month") +
ylab("Total Tweets") +
scale_x_discrete(breaks=1:30, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D", "J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D", "J", "F", "M", "A", "M", "J"))
#LDA analysis in R
setwd("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets")
library(tidyverse)
library(lubridate)
dat2018<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedtweets2018.csv")
dat2019<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedtweets2019.csv") %>% filter(PUBLISH_DATE!= "")
dat2020<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedtweets2020.csv") %>% filter(PUBLISH_DATE!= "")
allData<- rbind(dat2018, dat2019, dat2020) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
group_by(tweetYear) %>% mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
ungroup()
representativeTweets2018<- dat2018 %>% group_by(Dominant_Topic) %>% top_n(200, Perc_Contribution)
data.table::fwrite(representativeTweets2018, file="representativeTweets2018.csv")
