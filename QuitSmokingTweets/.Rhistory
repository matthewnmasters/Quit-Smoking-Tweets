runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
?summarise_each
runApp('GitHub/Fantasy-Football')
?mean
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp()
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
?accross
?across
runApp('GitHub/Fantasy-Football')
runApp()
runApp('GitHub/Fantasy-Football')
runApp()
runApp('GitHub/Fantasy-Football')
?summarise_each
runApp('GitHub/Fantasy-Football')
?round
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
?renderDataTable
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
?options
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp()
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
runApp('GitHub/Fantasy-Football')
wordList <- readLines("C:/Users/matth/Documents/GitHub/Riddler-Solutions/wordList.txt")
wordList[3]
wordList[4]
wordDF <- data.frame(wordList)
View(wordDF)
library(stringr)
View(wordDF)
str_extract(wordList)
str_extract_all(wordList)
str_extract_all(wordList, boundary("character"))
wordDF <- dataframe(str_extract_all(wordList, boundary("character")))
wordDF <- data.frame(str_extract_all(wordList, boundary("character")))
View(wordDF)
wordDF <- data.frame(str_extract_all(wordList, boundary("character")))
words <- str_extract_all(wordList, boundary("character"))
View(words)
wordDF <- data.frame(words)
words <- unlist(str_extract_all(wordList, boundary("character")))
wordDF <- data.frame(words)
View(wordDF)
words <- str_extract_all(wordList, boundary("character"))
words <- str_split_fixed(wordList)
?str_split_fixed
words <- str_split_fixed(wordList, boundary("character"))
words <- str_split(wordList, boundary("character"))
View(words)
wordDF <- data.frame(words)
wordList <- readLines("C:/Users/matth/Documents/GitHub/Riddler-Solutions/wordList.txt")
wordList <- readLines("C:/Users/matth/Documents/GitHub/Riddler-Solutions/wordList.txt")
wordDF <- data.frame(wordList)
wordDF <- data.frame(wordList)
View(wordDF)
library(stringr)
wordList <- readLines("C:/Users/matth/Documents/GitHub/Riddler-Solutions/wordList.txt")
wordDF <- data.frame(wordList)
str_extract_all(wordDF$wordList, boundary("character"))
x <- str_extract_all(wordDF$wordList, boundary("character"))
View(x)
max(wordDF$wordList)
max(len(wordDF$wordList))
max(length(wordDF$wordList))
max(length(wordDF$wordList[]))
length(wordDF$wordList[[]])
length(wordDF$wordList[)
length(wordDF$wordList[]
length(wordDF$wordList[])
wordList <- readLines("C:/Users/matth/Documents/GitHub/Riddler-Solutions/wordList.txt")
wordDF <- data.frame(wordList)
library(dplyr)
wordDF <- data.frame(wordList) %>% separ
library(dplyr)
wordDF <- data.frame(wordList) %>% separate(wordList)
?separate
library(tidyverse)
wordDF <- data.frame(wordList) %>% separate(wordList)
?separate()
wordDF <- data.frame(wordList) %>% separate(wordList, sep = "", fill="right")
wordDF <- data.frame(wordList) %>% separate(wordList, sep = "")
wordDF <- data.frame(wordList) %>% separate(wordList, sep = "", fill="right", into = c("1", "2", "3", "4", "5", "6", "7"))
wordDF <- data.frame(wordList) %>% separate(wordList, sep = ".", fill="right", into = c("1", "2", "3", "4", "5", "6", "7"))
View(wordDF)
wordDF <- data.frame(wordList)
View(wordDF)
x<-separate(wordDF$wordList, sep = ".", fill="right", into = c("1", "2", "3", "4", "5", "6", "7"))
wordDF <- separate(wordDF$wordList, sep = ".", fill="right", into = c("1", "2", "3", "4", "5", "6", "7"))
wordDF <- data.frame(wordList) %>%
separate(wordDF$wordList, sep = ".")
wordDF <- data.frame(wordList) %>%
separate(wordDF$wordList, sep = ".")
wordDF <- data.frame(wordList) %>%
separate(wordList, sep = ".")
wordDF <- data.frame(wordList)
View(wordDF)
separate(wordDF$wordList, sep = ".")
separate(wordList, sep = ".")
library(data.table)
wordList <- readLines("C:/Users/matth/Documents/GitHub/Riddler-Solutions/wordList.txt")
wordDF <- data.table(wordList)
View(wordDF)
wordDT <- data.table(wordList)
View(wordDT)
?tstrsplit
wordDT_Wide <- wordDT[, tstrsplit(wordList, "")]
View(wordDT_Wide)
wordList <- readLines("C:/Users/matth/Documents/GitHub/Riddler-Solutions/wordList.txt")
wordDF <- data.table(wordList)
wordDF_Wide <- transpose(strsplit(wordDF$wordList))
?strsplit
wordDF_Wide <- transpose(strsplit(wordDF$wordList, split="."))
View(wordDF_Wide)
wordDF <- data.frame(wordList)
wordDF <- data.frame(wordList)
wordDF_Wide <- transpose(strsplit(wordDF$wordList, split="."))
View(wordDF_Wide)
wordDF_Wide <- data.frame(transpose(strsplit(wordDF$wordList, split=".")))
View(wordDF_Wide)
wordDF_Wide <- data.frame(transpose(strsplit(wordDF$wordList, split="")))
View(wordDF_Wide)
library(tidyverse)
wordList <- readLines("C:/Users/matth/Documents/GitHub/Riddler-Solutions/wordList.txt")
wordDF_Wide <- data.frame(transpose(strsplit(wordList, split="")))
View(wordDF_Wide)
wordDF_Wide <- data.frame(transpose(strsplit(wordList, split=""))) %>% colnames(, 1:28)
wordDF_Wide <- data.frame(transpose(strsplit(wordList, split=""))) %>% colnames(, c(1:28))
wordDF_Wide <- data.frame(transpose(strsplit(wordList, split=""))) %>% colnames(., c(1:28))
?rename_all
wordDF_Wide <- data.frame(transpose(strsplit(wordList, split=""))) %>% colnames(., as.character(1:28))
?colnames
wordDF_Wide <- data.frame(transpose(strsplit(wordList, split=""))) %>% rename_all(1:28)
wordDF_Wide <- data.frame(transpose(strsplit(wordList, split=""))) %>% colnames(.) <-1:28
wordDF_Wide <- data.frame(transpose(strsplit(wordList, split="")))
View(wordDF_Wide)
colnames(wordDF_Wide) <- 1:28
View(wordDF_Wide)
colnames(wordDF_Wide) <- letters[1:28]
View(wordDF_Wide)
table(wordDF_Wide[a])
table(wordDF_Wide$a)
count(wordDF_Wide$a)
?count
count(wordDF_Wide$a)
table(wordDF_Wide$a)
tally(wordDF_Wide$a)
table(wordDF_Wide$a)
wordDF_Wide %>% count(a)
colnames(wordDF_Wide) <- 1:28
wordDF_Wide %>% count(1)
colnames(wordDF_Wide) <- c(LETTERS[1:26], "aa", "bb")
View(wordDF_Wide)
wordDF_Wide %>% count(a)
table(wordDF_Wide$A)
table(wordDF_Wide$B)
table(wordDF_Wide$C)
table(wordDF_Wide$D)
table(wordDF_Wide$E)
x<-table(wordDF_Wide$A)
first <- as.vector(table(wordDF_Wide$A))
x<- data.frame(letters = LETTERS[1:26], one = first, two = second, three = third, four = fourth, five = fifth)
first <- as.vector(table(wordDF_Wide$A))
second <- as.vector(table(wordDF_Wide$B))
third <- as.vector(table(wordDF_Wide$C))
fourth <- as.vector(table(wordDF_Wide$D))
fifth <- as.vector(table(wordDF_Wide$E))
x<- data.frame(letters = LETTERS[1:26], one = first, two = second, three = third, four = fourth, five = fifth)
View(x)
wordDF_Wide <- wordDF_Wide %>% filter(is.na(B) == FALSE, is.na(C) == FALSE, is.na(D) == FALSE, is.na(E) == FALSE, is.na(F) == TRUE)
View(wordDF_Wide)
onlyFive <- wordDF_Wide %>% filter(is.na(B) == FALSE, is.na(C) == FALSE, is.na(D) == FALSE, is.na(E) == FALSE, is.na(F) == TRUE) %>%
select(A, B, C, D, E)
View(onlyFive)
View(onlyFive)
View(onlyFive)
first <- as.vector(table(onlyFive$A))
second <- as.vector(table(onlyFive$B))
third <- as.vector(table(onlyFive$C))
fourth <- as.vector(table(onlyFive$D))
fifth <- as.vector(table(onlyFive$E))
x<- data.frame(letters = LETTERS[1:26], one = first, two = second, three = third, four = fourth, five = fifth)
table(onlyFive$D
table(onlyFive$D)
table(onlyFive$D)
################################################################################
#Updated the data for new analyses                                             #
################################################################################
#LDA analysis in R
setwd("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets")
library(tidyverse)
library(lubridate)
dat2018<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWide2018.csv")
dat2019<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWide2019.csv") %>% filter(PUBLISH_DATE!= "")
dat2019<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWide2019.csv")
dat2020<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWide2020.csv")
dat2020<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWide2020.csv") %>% filter(PUBLISH_DATE!= "")
datNEW<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWideNEW.csv")
?ungroup
allData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>% ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
View(allData)
allData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
View(allData)
View(allData)
allData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) %>% #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
select(AUTHOR, CONTENT, newDate, zero_top, zero_perc, one_top, one_perc, two_top, two, perc, three_top, three_perc, four_top, four_perc, five_top, five_perc, six_top, six_perc, seven_top, seven_perc, eight_top, eight_perc, nine_top, nine_perc)
allData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) %>% #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
select(AUTHOR, CONTENT, newDate, zero_top, zero_perc, one_top, one_perc, two_top, two_perc, three_top, three_perc, four_top, four_perc, five_top, five_perc, six_top, six_perc, seven_top, seven_perc, eight_top, eight_perc, nine_top, nine_perc)
View(allData)
allData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) %>% #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
select(ARTICLE_URL, zero_top, zero_perc, one_top, one_perc, two_top, two_perc, three_top, three_perc, four_top, four_perc, five_top, five_perc, six_top, six_perc, seven_top, seven_perc, eight_top, eight_perc, nine_top, nine_perc)
View(allData)
allData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) %>% #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
select(ARTICLE_URL, newDate, tweetYear, tweetWeek, tweetMonth, zero_top, zero_perc, one_top, one_perc, two_top, two_perc, three_top, three_perc, four_top, four_perc, five_top, five_perc, six_top, six_perc, seven_top, seven_perc, eight_top, eight_perc, nine_top, nine_perc)
View(allData)
allData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) %>% #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, zero_top, zero_perc, one_top, one_perc, two_top, two_perc, three_top, three_perc, four_top, four_perc, five_top, five_perc, six_top, six_perc, seven_top, seven_perc, eight_top, eight_perc, nine_top, nine_perc)
View(allData)
?gather
test<- gather(allData, ARTICLE_URL)
View(test)
test<- gather(allData, "value", ARTICLE_URL, newDate, tweetMonth, tweetWeek)
View(test)
test<- gather(allData, value="value", key= ARTICLE_URL, newDate, tweetMonth, tweetWeek)
View(test)
?melt
test <- melt(allData, id=c("ARTICLE_URL"), na.rm=TRUE)
??melt
test <- reshape2::melt(allData, id=c("ARTICLE_URL"), na.rm=TRUE)
View(test)
test <- reshape2::melt(allData, id=c("ARTICLE_URL", "newDate", "tweetYear"), na.rm=TRUE)
View(test)
test <- reshape2::melt(allData, id=c("ARTICLE_URL", "newDate", "tweetYear", "tweetMonth", "tweetWeek"), na.rm=TRUE)
View(test)
View(test)
longTopics <- reshape2::melt(allData, id=c("ARTICLE_URL", "newDate", "tweetYear", "tweetMonth", "tweetWeek"), na.rm=TRUE) %>%
filter(grepl("top", .variable))
longTopics <- reshape2::melt(allData, id=c("ARTICLE_URL", "newDate", "tweetYear", "tweetMonth", "tweetWeek"), na.rm=TRUE) %>%
filter(grepl("top", .$variable))
View(test)
longTopics <- reshape2::melt(allData, id=c("ARTICLE_URL", "newDate", "tweetYear", "tweetMonth", "tweetWeek"), na.rm=TRUE) %>%
filter(grepl("top", .$variable)==TRUE)
View(longTopics)
longTopics <- allData %>%
select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, zero_top, zero_perc, one_top, one_perc, two_top, two_perc, three_top, three_perc, four_top, four_perc, five_top, five_perc, six_top, six_perc, seven_top, seven_perc, eight_top, eight_perc, nine_top, nine_perc) %>%
reshape2::melt(., id=c("ARTICLE_URL", "newDate", "tweetYear", "tweetMonth", "tweetWeek"), na.rm=TRUE) %>%
filter(grepl("top", .$variable)==TRUE)
################################################################################
#Updated the data for new analyses                                             #
################################################################################
#LDA analysis in R
setwd("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets")
library(tidyverse)
library(lubridate)
dat2018<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWide2018.csv")
dat2019<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWide2019.csv")
dat2020<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWide2020.csv")
datNEW<- read.csv("C:/Users/matth/Documents/GitHub/QS2020/QuitSmokingTweets/processedWideNEW.csv")
allData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
A <- alldata %>% select(ARTICLE_URL, zero_top, zero_perc)
A <- allData %>% select(ARTICLE_URL, zero_top, zero_perc)
View(A)
B <- allData %>% select(ARTICLE_URL, one_top, one_perc)
View(B)
B <- allData %>% select(ARTICLE_URL, one_top, one_perc) %>% filter(is.na(one_top)==FALSE)
View(B)
wideData<- rbind(dat2018, dat2019, dat2020, datNEW) %>% mutate(newDate=as.Date(PUBLISH_DATE, "%m/%d/%Y")) %>%
mutate(tweetYear= year(newDate), tweetMonth= month(newDate), tweetDay=day(newDate)) %>%
group_by(tweetYear) %>% add_count(tweetYear, name="totalYearlyTweets") %>%
group_by(tweetMonth) %>% add_count(tweetMonth, name= "totalMonthlyTweets") %>%
ungroup() %>%
mutate(tweetWeek= week(newDate)) %>% add_count(tweetWeek, name= "totalWeeklyTweets") %>% #isoweek instead of week is probably needed for Trends data
distinct(ARTICLE_URL, .keep_all = TRUE) #when we brought in the new data there was overlap but we didnt remove it in the code because we needed identical dictionaries
A <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, zero_top, zero_perc)
B <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, one_top, one_perc) %>% filter(is.na(one_top)==FALSE)
C <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, two_top, two_perc) %>% filter(is.na(two_top)==FALSE)
D <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, three_top, three_perc) %>% filter(is.na(three_top)==FALSE)
E <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, four_top, four_perc) %>% filter(is.na(four_top)==FALSE)
G <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, five_top, five_perc) %>% filter(is.na(five_top)==FALSE)
H <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, six_top, six_perc) %>% filter(is.na(six_top)==FALSE)
I <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, seven_top, seven_perc) %>% filter(is.na(seven_top)==FALSE)
J <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, eight_top, eight_perc) %>% filter(is.na(eight_top)==FALSE)
K <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, nine_top, nine_perc) %>% filter(is.na(nine_top)==FALSE)
longData<- rbind(A,B,C,D,E,G,H,I,J,K)
#Separate out the topics and percentages, along with the date for graphing and the unique ID variable (ARTICLE_URL)
A <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, zero_top, zero_perc) %>% rename(Topic = zero_top, Probability = zero_perc)
A <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, zero_top, zero_perc) %>% rename(Topic = zero_top, Probability = zero_perc)
B <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, one_top, one_perc) %>% filter(is.na(one_top)==FALSE) %>% rename(Topic = one_top, Probability = one_perc)
C <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, two_top, two_perc) %>% filter(is.na(two_top)==FALSE) %>% rename(Topic = two_top, Probability = two_perc)
D <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, three_top, three_perc) %>% filter(is.na(three_top)==FALSE) %>% rename(Topic = three_top, Probability = three_perc)
E <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, four_top, four_perc) %>% filter(is.na(four_top)==FALSE) %>% rename(Topic = four_top, Probability = four_perc)
G <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, five_top, five_perc) %>% filter(is.na(five_top)==FALSE) %>% rename(Topic = five_top, Probability = five_perc)
H <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, six_top, six_perc) %>% filter(is.na(six_top)==FALSE) %>% rename(Topic = six_top, Probability = six_perc)
I <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, seven_top, seven_perc) %>% filter(is.na(seven_top)==FALSE) %>% rename(Topic = seven_top, Probability = seven_perc)
J <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, eight_top, eight_perc) %>% filter(is.na(eight_top)==FALSE) %>% rename(Topic = eight_top, Probability = eight_perc)
K <- wideData %>% select(ARTICLE_URL, newDate, tweetYear, tweetMonth, tweetWeek, nine_top, nine_perc) %>% filter(is.na(nine_top)==FALSE) %>% rename(Topic = nine_top, Probability = nine_perc)
longData<- rbind(A,B,C,D,E,G,H,I,J,K)
View(longData)
longData<- rbind(A,B,C,D,E,G,H,I,J,K) %>% group_by(ARTICLE_URL) %>% arrange(desc(Probability), .by_group=FALSE)
View(longData)
longData<- rbind(A,B,C,D,E,G,H,I,J,K) %>% group_by(ARTICLE_URL) %>% arrange(desc(Probability), .by_group=TRUE)
View(longData)
?count()
summedLong<- longData %>% group_by(newDate) %>% count(Topic, wt=Probability)
View(summedLong)
ggplot(summedLong, aes(newDate,n)) + geom_line()
ggplot(summedLong, aes(newDate,n, group=Topic)) + geom_line()
noSpamSummedLong<- summedLong %>% filter(Topic %in% c(0,1,4,6,7,8))
ggplot(summedLong, aes(x=newDate, y=n, group=Topic)) + geom_line()
ggplot(noSpamSummedLong, aes(x=newDate, y=n, group=Topic)) + geom_line()
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability)
View(monthlySummedLong)
View(monthlySummedLong)
MonthlyNoSpamSummedLong<- summedLong %>% filter(Topic %in% c(0,1,4,6,7,8))
View(monthlySummedLong)
?case_when
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
case_when(tweetYear == 2019 ~ tweetMonth + 12,
tweetYear == 2020 ~ tweethMonth +24)
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
mutate(tweetMonth = case_when(tweetYear == 2019 ~ tweetMonth + 12,
tweetYear == 2020 ~ tweethMonth +24))
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
ungroup() %>%
mutate(newTweetMonth = case_when(tweetYear == 2019 ~ tweetMonth + 12,
tweetYear == 2020 ~ tweethMonth +24))
View(monthlySummedLong)
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
ungroup() %>%
mutate(newTweetMonth = case_when(tweetYear == 2019 ~ (tweetMonth + 12)))
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
ungroup() %>%
mutate(newTweetMonth = case_when(tweetYear == 2019 ~ (tweetMonth + 12),
tweetYear == 2020 ~ (tweetMonth +24)))
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
mutate(newTweetMonth = case_when(tweetYear == 2019 ~ (tweetMonth + 12),
tweetYear == 2020 ~ (tweetMonth +24)))
View(monthlySummedLong)
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
mutate(newTweetMonth = case_when(tweetYear == 2018 ~ (tweetMonth + 0),
tweetYear == 2019 ~ (tweetMonth + 12),
tweetYear == 2020 ~ (tweetMonth +24)))
View(monthlySummedLong)
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
mutate(tweetMonth = case_when(tweetYear == 2018 ~ (tweetMonth + 0),
tweetYear == 2019 ~ (tweetMonth + 12),
tweetYear == 2020 ~ (tweetMonth +24)))
View(monthlySummedLong)
MonthlyNoSpamSummedLong<- monthlySummedLong %>% filter(Topic %in% c(0,1,4,6,7,8))
monthlyNoSpamSummedLong<- monthlySummedLong %>% filter(Topic %in% c(0,1,4,6,7,8))
ggplot(monthlyNoSpamSummedLong, aes(x=, y=n, group=Topic)) + geom_line()
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) + geom_line()
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line() +
scale_x_discrete(breaks=1:12, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line() +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line() +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line()
monthlyNoSpamSummedLong<- monthlySummedLong %>% filter(Topic %in% c(0,1,4,6,7,8)) %>% mutate(tweetMonth = as.factor(tweetMonth))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line() +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
mutate(tweetMonth = case_when(tweetYear == 2018 ~ (tweetMonth + 0),
tweetYear == 2019 ~ (tweetMonth + 12),
tweetYear == 2020 ~ (tweetMonth +24)))  %>%
mutate(tweetMonth = as.factor(tweetMonth), Topic = as.factor(Topic))
monthlyNoSpamSummedLong<- monthlySummedLong %>% filter(Topic %in% c(0,1,4,6,7,8))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(size=3, shape=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(size=2, shape=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(size=2, color=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(size=1.5, color=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(color=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(color=Topic, shape=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(color=Topic, shape=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))+
geom_vline(xintercept = c(12.5,24.5))
monthlySummedLong<- longData %>% group_by(tweetYear,tweetMonth) %>% count(Topic, wt=Probability) %>%
mutate(tweetMonth = case_when(tweetYear == 2018 ~ (tweetMonth + 0),
tweetYear == 2019 ~ (tweetMonth + 12),
tweetYear == 2020 ~ (tweetMonth +24)))  %>%
mutate(Topic = case_when(Topic == 0 ~ "Health Ch",
Topic == 1 ~ "Need 2 Qt",
Topic == 4 ~ "E-Cig",
Topic == 6 ~ "Clinics/Serv",
Topic == 7 ~ "Advice/Suc",
Topic == 8 ~ "Personal Ex")) %>%
mutate(tweetMonth = as.factor(tweetMonth))
monthlyNoSpamSummedLong<- monthlySummedLong %>% filter(Topic %in% c(0,1,4,6,7,8))
View(monthlySummedLong)
monthlyNoSpamSummedLong<- monthlySummedLong %>% filter(is.na(Topic)==FALSE)
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(color=Topic, shape=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))+
geom_vline(xintercept = c(12.5,24.5))
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(color=Topic, shape=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))+
geom_vline(xintercept = c(12.5,24.5)) +
ylab("Weighted Total Tweets")
ggplot(monthlyNoSpamSummedLong, aes(x=tweetMonth, y=n, group=Topic)) +
geom_line(aes(color=Topic)) +
geom_point(aes(color=Topic, shape=Topic)) +
scale_x_discrete(breaks=1:36, labels=c("J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D","J", "F", "M", "A", "M", "J", "J", "A", "S", "O", "N","D"))+
geom_vline(xintercept = c(12.5,24.5)) +
ylab("Weighted Total Tweets") +
xlab("Month")
